# Graph Metrics ç¯„ä¾‹

æ­¤ç¯„ä¾‹æ¼”ç¤ºäº†å¦‚ä½•åœ¨ Semantic Kernel Graph å·¥ä½œæµç¨‹ä¸­æ”¶é›†ã€ç›£æ§å’Œåˆ†ææ•ˆèƒ½æŒ‡æ¨™ã€‚å®ƒå±•ç¤ºäº†å¦‚ä½•ç‚º Graph åŸ·è¡Œå¯¦æ–½å…¨é¢çš„å¯è§€æ¸¬æ€§ï¼ŒåŒ…æ‹¬ç¯€é»å±¤ç´šçš„æŒ‡æ¨™ã€åŸ·è¡Œè·¯å¾‘å’Œæ•ˆèƒ½åˆ†æã€‚

## ç›®æ¨™

å­¸ç¿’å¦‚ä½•åœ¨åŸºæ–¼ Graph çš„å·¥ä½œæµç¨‹ä¸­å¯¦æ–½å…¨é¢çš„æŒ‡æ¨™å’Œç›£æ§ï¼Œä»¥ä¾¿ï¼š
* åœ¨ Graph åŸ·è¡ŒæœŸé–“æ”¶é›†å³æ™‚æ•ˆèƒ½æŒ‡æ¨™
* ç›£æ§ç¯€é»åŸ·è¡Œæ™‚é–“ã€æˆåŠŸç‡å’Œè³‡æºä½¿ç”¨ç‹€æ³
* åˆ†æåŸ·è¡Œè·¯å¾‘ä¸¦è­˜åˆ¥æ•ˆèƒ½ç“¶é ¸
* å°‡æŒ‡æ¨™åŒ¯å‡ºåˆ°å„ç¨®ç›£æ§ç³»çµ±å’Œå„€è¡¨æ¿
* ç‚ºç”Ÿç”¢å·¥ä½œæµç¨‹å¯¦æ–½è‡ªè¨‚æŒ‡æ¨™å’Œè­¦ç¤º

## å‰ç½®æ¢ä»¶

* **.NET 8.0** æˆ–æ›´æ–°ç‰ˆæœ¬
* **OpenAI API é‡‘é‘°**å·²é…ç½®åœ¨ `appsettings.json` ä¸­
* å·²å®‰è£ **Semantic Kernel Graph å¥—ä»¶**
* å° [Graph Concepts](../concepts/graph-concepts.md) å’Œ [Metrics Concepts](../concepts/metrics.md) çš„åŸºæœ¬ç†è§£

## ä¸»è¦å…ƒä»¶

### æ¦‚å¿µå’ŒæŠ€è¡“

* **Performance Metrics**ï¼šåŸ·è¡Œæ•ˆèƒ½è³‡æ–™çš„æ”¶é›†å’Œåˆ†æ
* **Node Monitoring**ï¼šå€‹åˆ¥ç¯€é»åŸ·è¡Œçš„å³æ™‚ç›£æ§
* **Execution Path Analysis**ï¼šé€é Graph è¿½è¹¤å’Œåˆ†æåŸ·è¡Œæµ
* **Resource Monitoring**ï¼šç›£æ§ CPUã€è¨˜æ†¶é«”å’Œå…¶ä»–è³‡æºä½¿ç”¨
* **Metrics Export**ï¼šå°‡æŒ‡æ¨™åŒ¯å‡ºåˆ°ç›£æ§ç³»çµ±å’Œå„€è¡¨æ¿

### æ ¸å¿ƒé¡åˆ¥

* `GraphPerformanceMetrics`ï¼šæ ¸å¿ƒæŒ‡æ¨™æ”¶é›†å’Œç®¡ç†
* `NodeExecutionMetrics`ï¼šå€‹åˆ¥ç¯€é»æ•ˆèƒ½è¿½è¹¤
* `MetricsDashboard`ï¼šå³æ™‚æŒ‡æ¨™è¦–è¦ºåŒ–å’Œåˆ†æ
* `GraphMetricsExporter`ï¼šå°‡æŒ‡æ¨™åŒ¯å‡ºåˆ°å¤–éƒ¨ç³»çµ±

## åŸ·è¡Œç¯„ä¾‹

### å…¥é–€æŒ‡å—

æ­¤ç¯„ä¾‹ä½¿ç”¨ Semantic Kernel Graph å¥—ä»¶æ¼”ç¤ºäº†æŒ‡æ¨™æ”¶é›†å’Œæ•ˆèƒ½ç›£æ§ã€‚ä¸‹åˆ—ç¨‹å¼ç¢¼ç‰‡æ®µå±•ç¤ºäº†å¦‚ä½•åœ¨è‡ªå·±çš„æ‡‰ç”¨ç¨‹å¼ä¸­å¯¦æ–½æ­¤æ¨¡å¼ã€‚

## é€æ­¥å¯¦æ–½

### 1. åŸºæœ¬æŒ‡æ¨™æ”¶é›†

æ­¤ç¯„ä¾‹æ¼”ç¤ºäº†åœ¨ Graph åŸ·è¡ŒæœŸé–“é€²è¡ŒåŸºæœ¬æŒ‡æ¨™æ”¶é›†ã€‚

```csharp
// Create development-friendly metrics options (short intervals for demos)
var options = GraphMetricsOptions.CreateDevelopmentOptions();
options.EnableResourceMonitoring = false; // keep the demo deterministic

// Create the metrics collector using the options
using var metrics = new GraphPerformanceMetrics(options);

// Simulate a few node executions and record metrics for each
for (int i = 0; i < 5; i++)
{
    var execId = $"exec-{i}";

    // Start tracking a node execution
    var tracker = metrics.StartNodeTracking($"node-{i}", $"node-name-{i}", execId);

    // Simulate work
    await Task.Delay(10 + i * 5);

    // Mark completion and record an execution path for analysis
    metrics.CompleteNodeTracking(tracker, success: true, result: null);
    metrics.RecordExecutionPath(execId, new[] { tracker.NodeId }, TimeSpan.FromMilliseconds(10 + i * 5), success: true);
}

// Export a preview using the metrics exporter
using var exporter = new GraphMetricsExporter();
var json = exporter.ExportMetrics(metrics, MetricsExportFormat.Json, TimeSpan.FromMinutes(10));
Console.WriteLine("\n--- JSON Export Preview ---\n");
Console.WriteLine(json.Substring(0, Math.Min(800, json.Length)));

var prometheus = exporter.ExportMetrics(metrics, MetricsExportFormat.Prometheus, TimeSpan.FromMinutes(10));
Console.WriteLine("\n--- Prometheus Export Preview ---\n");
Console.WriteLine(prometheus.Substring(0, Math.Min(800, prometheus.Length)));
```

### 2. é€²éšæ•ˆèƒ½ç›£æ§

æ¼”ç¤ºå…·æœ‰è©³ç´°æŒ‡æ¨™æ”¶é›†çš„å…¨é¢æ•ˆèƒ½ç›£æ§ã€‚

```csharp
// Create development options and a metrics collector suitable for profiling demos
var options = GraphMetricsOptions.CreateDevelopmentOptions();
using var metrics = new GraphPerformanceMetrics(options);

// Simulate an expensive operation and record detailed timing information
var execId = "advanced-exec-1";
var tracker = metrics.StartNodeTracking("performance-node", "performance-node", execId);
var stopwatch = System.Diagnostics.Stopwatch.StartNew();

// Simulate CPU-bound work with occasional awaits to avoid blocking the thread pool
int iterations = 10_000;
long result = 0;
for (int i = 0; i < iterations; i++)
{
    result += i * i;
    if (i % 1000 == 0) await Task.Delay(1); // cooperative pause to keep responsiveness
}

stopwatch.Stop();
metrics.CompleteNodeTracking(tracker, success: true, result: result);

// Use exporter to inspect metrics after the simulated workload
using var exporter = new GraphMetricsExporter();
Console.WriteLine(exporter.ExportMetrics(metrics, MetricsExportFormat.Json, TimeSpan.FromMinutes(10)));
```

### 3. å³æ™‚æŒ‡æ¨™å„€è¡¨æ¿

å±•ç¤ºå¦‚ä½•å¯¦æ–½å³æ™‚æŒ‡æ¨™è¦–è¦ºåŒ–å’Œç›£æ§ã€‚

```csharp
// Demonstrate basic real-time sampling using the metrics collector's resource sampling
var options = GraphMetricsOptions.CreateDevelopmentOptions();
options.EnableResourceMonitoring = true;
using var metrics = new GraphPerformanceMetrics(options);

// Simulate a stream of short executions and display sampled CPU/memory
for (int i = 0; i < 10; i++)
{
    var execId = $"rt-{i}";
    var tracker = metrics.StartNodeTracking("data-generator", "data-generator", execId);

    // Simulate some processing latency
    await Task.Delay(Random.Shared.Next(50, 200));

    metrics.CompleteNodeTracking(tracker, success: true);

    // Read current sampled system metrics (collector updates them periodically)
    Console.WriteLine($"Iteration {i + 1}: CPU={metrics.CurrentCpuUsage:F1}% Memory={metrics.CurrentAvailableMemoryMB:F0} MB");

    await Task.Delay(500); // throttle updates for the demo
}

Console.WriteLine("âœ… Real-time sampling demo completed");
```

### 4. æŒ‡æ¨™åŒ¯å‡ºå’Œæ•´åˆ

æ¼”ç¤ºå°‡æŒ‡æ¨™åŒ¯å‡ºåˆ°å¤–éƒ¨ç›£æ§ç³»çµ±å’Œå„€è¡¨æ¿ã€‚

```csharp
// Export example using the metrics exporter directly
using var exporter = new GraphMetricsExporter(new GraphMetricsExportOptions { IndentedOutput = true });

// Export JSON
var jsonExport = exporter.ExportMetrics(metrics, MetricsExportFormat.Json, TimeSpan.FromMinutes(10));
Console.WriteLine("--- JSON Export ---");
Console.WriteLine(jsonExport);

// Export CSV
var csvExport = exporter.ExportMetrics(metrics, MetricsExportFormat.Csv, TimeSpan.FromMinutes(10));
Console.WriteLine("--- CSV Export ---");
Console.WriteLine(csvExport.Split('\n').Take(20)); // preview first lines

// Export Prometheus
var promExport = exporter.ExportMetrics(metrics, MetricsExportFormat.Prometheus, TimeSpan.FromMinutes(10));
Console.WriteLine("--- Prometheus Export ---");
Console.WriteLine(promExport);
```

## é æœŸè¼¸å‡º

### åŸºæœ¬æŒ‡æ¨™æ”¶é›†ç¯„ä¾‹

```
ğŸ“Š Testing metrics collection: Sample data 1
   Processing Time: 234.56 ms
   Input Size: 12 characters
   Metrics Collected: 5 metrics

ğŸ“Š Testing metrics collection: Sample data 2
   Processing Time: 187.23 ms
   Input Size: 12 characters
   Metrics Collected: 5 metrics
```

### é€²éšæ•ˆèƒ½ç›£æ§ç¯„ä¾‹

```
ğŸš€ Testing performance monitoring: Low complexity task
   Complexity Level: 1
   Processing Time: 156.78 ms
   Iterations: 1,000
   Throughput: 6,374 ops/sec
   Performance Score: 85.67
   Bottleneck: CPU-bound

ğŸš€ Testing performance monitoring: High complexity task
   Complexity Level: 10
   Processing Time: 1,234.56 ms
   Iterations: 10,000
   Throughput: 8,101 ops/sec
   Performance Score: 92.34
   Bottleneck: Memory-bound
```

### å³æ™‚æŒ‡æ¨™å„€è¡¨æ¿ç¯„ä¾‹

```
ğŸ“Š Starting real-time metrics collection...
   Dashboard will update every 500ms
   Press any key to stop...
   Iteration 1: Current: 87.45, Avg: 87.45, Trend: stable
   Iteration 2: Current: 112.34, Avg: 99.90, Trend: increasing
   Iteration 3: Current: 95.67, Avg: 98.49, Trend: decreasing
âœ… Real-time metrics collection completed
```

### æŒ‡æ¨™åŒ¯å‡ºç¯„ä¾‹

```
ğŸ“¤ Testing metrics export: 10 executions
   Success Rate: 90.0%
   Average Time: 150.00 ms
   Export Formats: json, csv, prometheus, monitoring

ğŸ“¤ Testing metrics export: 50 executions
   Success Rate: 96.0%
   Average Time: 150.00 ms
   Export Formats: json, csv, prometheus, monitoring
```

## è¨­å®šé¸é …

### æŒ‡æ¨™è¨­å®š

```csharp
var metricsOptions = new GraphMetricsOptions
{
    EnableNodeMetrics = true,                        // Enable node-level metrics
    EnableExecutionMetrics = true,                   // Enable execution-level metrics
    EnableResourceMetrics = true,                    // Enable resource usage metrics
    EnableCustomMetrics = true,                      // Enable custom metrics
    EnablePerformanceProfiling = true,               // Enable performance profiling
    EnableRealTimeMetrics = true,                    // Enable real-time metrics
    EnableMetricsStreaming = true,                   // Enable metrics streaming
    EnableMetricsDashboard = true,                   // Enable metrics dashboard
    EnableMetricsExport = true,                      // Enable metrics export
    EnableMetricsPersistence = true,                 // Enable metrics persistence
    MetricsCollectionInterval = TimeSpan.FromMilliseconds(100), // Collection interval
    DashboardUpdateInterval = TimeSpan.FromMilliseconds(500),   // Dashboard update interval
    ExportInterval = TimeSpan.FromSeconds(5),        // Export interval
    MetricsStoragePath = "./metrics-data",           // Metrics storage path
    ExportFormats = new[] { "json", "csv", "prometheus" },     // Export formats
    EnableMetricsCompression = true,                 // Enable metrics compression
    MaxMetricsHistory = 10000,                       // Maximum metrics history
    EnableMetricsAggregation = true,                 // Enable metrics aggregation
    AggregationInterval = TimeSpan.FromMinutes(1)    // Aggregation interval
};
```

### æ•ˆèƒ½åˆ†æè¨­å®š

```csharp
var profilingOptions = new PerformanceProfilingOptions
{
    EnableDetailedProfiling = true,                  // Enable detailed profiling
    EnableMemoryProfiling = true,                    // Enable memory profiling
    EnableCpuProfiling = true,                       // Enable CPU profiling
    EnableNetworkProfiling = true,                   // Enable network profiling
    ProfilingSamplingRate = 0.1,                     // Profiling sampling rate (10%)
    EnableHotPathAnalysis = true,                    // Enable hot path analysis
    EnableBottleneckDetection = true,                // Enable bottleneck detection
    ProfilingOutputPath = "./profiling-data",         // Profiling output path
    EnableProfilingVisualization = true,             // Enable profiling visualization
    MaxProfilingDataSize = 100 * 1024 * 1024        // Max profiling data size (100MB)
};
```

## ç–‘é›£æ’è§£

### å¸¸è¦‹å•é¡Œ

#### æœªæ”¶é›†æŒ‡æ¨™
```bash
# Problem: Metrics are not being collected
# Solution: Enable metrics collection and check configuration
EnableNodeMetrics = true;
EnableExecutionMetrics = true;
MetricsCollectionInterval = TimeSpan.FromMilliseconds(100);
```

#### æ•ˆèƒ½å½±éŸ¿
```bash
# Problem: Metrics collection impacts performance
# Solution: Adjust collection interval and enable sampling
MetricsCollectionInterval = TimeSpan.FromSeconds(1);
EnableMetricsSampling = true;
SamplingRate = 0.1; // 10% sampling
```

#### è¨˜æ†¶é«”å•é¡Œ
```bash
# Problem: Metrics consume too much memory
# Solution: Enable compression and limit history
EnableMetricsCompression = true;
MaxMetricsHistory = 1000;
EnableMetricsAggregation = true;
```

### é™¤éŒ¯æ¨¡å¼

å•Ÿç”¨è©³ç´°æ—¥èªŒä»¥é€²è¡Œç–‘é›£æ’è§£ï¼š

```csharp
// Enable debug logging
var logger = LoggerFactory.Create(builder =>
{
    builder.AddConsole();
    builder.SetMinimumLevel(LogLevel.Debug);
}).CreateLogger<GraphMetricsExample>();

// Configure metrics with debug logging
var debugMetricsOptions = new GraphMetricsOptions
{
    EnableNodeMetrics = true,
    EnableExecutionMetrics = true,
    EnableResourceMetrics = true,
    EnableDebugLogging = true,
    LogMetricsCollection = true,
    LogMetricsExport = true
};
```

## é€²éšæ¨¡å¼

### è‡ªè¨‚æŒ‡æ¨™æ”¶é›†

```csharp
// Implement custom metrics collection
public class CustomMetricsCollector : IMetricsCollector
{
    public async Task<Dictionary<string, object>> CollectMetricsAsync(MetricsContext context)
    {
        var customMetrics = new Dictionary<string, object>();
        
        // Collect custom business metrics
        customMetrics["business_value"] = await CalculateBusinessValue(context);
        customMetrics["user_satisfaction"] = await MeasureUserSatisfaction(context);
        customMetrics["cost_per_execution"] = await CalculateCostPerExecution(context);
        
        // Collect domain-specific metrics
        customMetrics["domain_accuracy"] = await MeasureDomainAccuracy(context);
        customMetrics["processing_efficiency"] = await MeasureProcessingEfficiency(context);
        
        return customMetrics;
    }
}
```

### æŒ‡æ¨™å½™ç¸½å’Œåˆ†æ

```csharp
// Implement custom metrics aggregation
public class MetricsAggregator : IMetricsAggregator
{
    public async Task<AggregatedMetrics> AggregateMetricsAsync(IEnumerable<MetricsSnapshot> snapshots)
    {
        var aggregated = new AggregatedMetrics();
        
        foreach (var snapshot in snapshots)
        {
            // Aggregate performance metrics
            aggregated.TotalExecutions += snapshot.ExecutionCount;
            aggregated.TotalProcessingTime += snapshot.TotalProcessingTime;
            aggregated.SuccessCount += snapshot.SuccessCount;
            aggregated.ErrorCount += snapshot.ErrorCount;
            
            // Track trends
            aggregated.ExecutionTrends.Add(snapshot.Timestamp, snapshot.ExecutionCount);
            aggregated.PerformanceTrends.Add(snapshot.Timestamp, snapshot.AverageProcessingTime);
        }
        
        // Calculate derived metrics
        aggregated.SuccessRate = (double)aggregated.SuccessCount / aggregated.TotalExecutions;
        aggregated.AverageProcessingTime = aggregated.TotalProcessingTime / aggregated.TotalExecutions;
        aggregated.ErrorRate = (double)aggregated.ErrorCount / aggregated.TotalExecutions;
        
        return aggregated;
    }
}
```

### å³æ™‚è­¦ç¤º

```csharp
// Implement real-time metrics alerting
public class MetricsAlerting : IMetricsAlerting
{
    private readonly List<AlertRule> _alertRules;
    
    public async Task<List<Alert>> CheckAlertsAsync(MetricsSnapshot metrics)
    {
        var alerts = new List<Alert>();
        
        foreach (var rule in _alertRules)
        {
            if (await rule.EvaluateAsync(metrics))
            {
                alerts.Add(new Alert
                {
                    RuleId = rule.RuleId,
                    Severity = rule.Severity,
                    Message = rule.GenerateMessage(metrics),
                    Timestamp = DateTime.UtcNow,
                    Metrics = metrics
                });
            }
        }
        
        return alerts;
    }
}

// Example alert rules
public class AlertRule
{
    public string RuleId { get; set; }
    public AlertSeverity Severity { get; set; }
    public Func<MetricsSnapshot, Task<bool>> Condition { get; set; }
    
    public static AlertRule CreateHighErrorRateRule()
    {
        return new AlertRule
        {
            RuleId = "high_error_rate",
            Severity = AlertSeverity.Critical,
            Condition = async (metrics) => metrics.ErrorRate > 0.1 // 10% error rate
        };
    }
}
```

## ç›¸é—œç¯„ä¾‹

* [Graph Visualization](./graph-visualization.md)ï¼šè¦–è¦ºåŒ–æŒ‡æ¨™è¡¨ç¤º
* [Performance Optimization](./performance-optimization.md)ï¼šä½¿ç”¨æŒ‡æ¨™é€²è¡Œæœ€ä½³åŒ–
* [Streaming Execution](./streaming-execution.md)ï¼šå³æ™‚æŒ‡æ¨™ä¸²æµ
* [Debug and Inspection](./debug-inspection.md)ï¼šç”¨æ–¼é™¤éŒ¯çš„æŒ‡æ¨™

## å¦è«‹åƒé–±

* [Metrics and Observability](../concepts/metrics.md)ï¼šç­è§£æŒ‡æ¨™æ¦‚å¿µ
* [Performance Monitoring](../how-to/performance-monitoring.md)ï¼šæ•ˆèƒ½ç›£æ§æ¨¡å¼
* [Debug and Inspection](../how-to/debug-and-inspection.md)ï¼šä½¿ç”¨æŒ‡æ¨™é€²è¡Œé™¤éŒ¯
* [API Reference](../api/)ï¼šå®Œæ•´ API æ–‡ä»¶
