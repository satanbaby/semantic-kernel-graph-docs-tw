# æ—¥èªŒè¨˜éŒ„ç¯„ä¾‹

æœ¬ç¯„ä¾‹å±•ç¤ºäº† Semantic Kernel Graph å·¥ä½œæµç¨‹ä¸­çš„å…¨é¢æ—¥èªŒè¨˜éŒ„å’Œçµæ§‹åŒ–æ—¥èªŒåŠŸèƒ½ã€‚å®ƒå±•ç¤ºäº†å¦‚ä½•å¯¦ç¾ä¸åŒçš„æ—¥èªŒç´šåˆ¥ã€çµæ§‹åŒ–æ—¥èªŒã€æ—¥èªŒèšåˆå’Œèˆ‡å„ç¨®æ—¥èªŒç³»çµ±çš„æ•´åˆã€‚

## ç›®æ¨™

å­¸ç¿’å¦‚ä½•åœ¨åŸºæ–¼åœ–å½¢çš„å·¥ä½œæµç¨‹ä¸­å¯¦ç¾å…¨é¢çš„æ—¥èªŒè¨˜éŒ„ä»¥ï¼š
* é…ç½®ä¸åŒçš„æ—¥èªŒç´šåˆ¥å’Œé¡åˆ¥
* å¯¦ç¾å…·æœ‰èªç¾©ä¿¡æ¯çš„çµæ§‹åŒ–æ—¥èªŒ
* èšåˆå’Œåˆ†æåœ–å½¢åŸ·è¡Œéç¨‹ä¸­çš„æ—¥èªŒ
* èˆ‡å¤–éƒ¨æ—¥èªŒç³»çµ±å’Œå„€è¡¨æ¿æ•´åˆ
* é€šéæ—¥èªŒç›£æ§å’Œèª¿è©¦åœ–å½¢åŸ·è¡Œ

## å‰ç½®è¦æ±‚

* **.NET 8.0** æˆ–æ›´é«˜ç‰ˆæœ¬
* **OpenAI API é‡‘é‘°**åœ¨ `appsettings.json` ä¸­é…ç½®
* **Semantic Kernel Graph å¥—ä»¶**å·²å®‰è£
* å°[åœ–å½¢æ¦‚å¿µ](../concepts/graph-concepts.md)å’Œ[æ—¥èªŒæ¦‚å¿µ](../concepts/logging.md)çš„åŸºæœ¬ç†è§£

## é—œéµçµ„ä»¶

### æ¦‚å¿µå’ŒæŠ€è¡“

* **çµæ§‹åŒ–æ—¥èªŒ**ï¼šå…·æœ‰çµæ§‹åŒ–æ•¸æ“šå’Œèªç¾©ä¿¡æ¯çš„æ—¥èªŒè¨˜éŒ„
* **æ—¥èªŒç´šåˆ¥**ï¼šä¸åŒç´šåˆ¥çš„æ—¥èªŒè©³ç´°ç¨‹åº¦ï¼ˆDebugã€Infoã€Warningã€Errorï¼‰
* **æ—¥èªŒèšåˆ**ï¼šè·¨åŸ·è¡Œæ”¶é›†å’Œåˆ†ææ—¥èªŒ
* **æ—¥èªŒé—œè¯**ï¼šå°‡æ—¥èªŒèˆ‡åŸ·è¡Œä¸Šä¸‹æ–‡å’Œç¯€é» ID ç›¸é—œè¯
* **æ—¥èªŒåŒ¯å‡º**ï¼šå°‡æ—¥èªŒåŒ¯å‡ºåˆ°å¤–éƒ¨ç³»çµ±å’Œå„€è¡¨æ¿

### æ ¸å¿ƒé¡åˆ¥

* `SemanticKernelGraphLogger`ï¼šæ ¸å¿ƒæ—¥èªŒå¯¦ç¾
* `GraphExecutionLogger`ï¼šåŸ·è¡Œç‰¹å®šçš„æ—¥èªŒè¨˜éŒ„
* `NodeExecutionLogger`ï¼šç¯€é»ç´šæ—¥èªŒè¨˜éŒ„
* `LogAggregator`ï¼šæ—¥èªŒé›†åˆå’Œåˆ†æ

## åŸ·è¡Œç¯„ä¾‹

### å…¥é–€

æœ¬ç¯„ä¾‹å±•ç¤ºäº† Semantic Kernel Graph å¥—ä»¶çš„å…¨é¢æ—¥èªŒè¨˜éŒ„å’Œè¿½è¹¤ã€‚ä¸‹é¢çš„ä»£ç¢¼ç‰‡æ®µå±•ç¤ºäº†å¦‚ä½•åœ¨è‡ªå·±çš„æ‡‰ç”¨ç¨‹åºä¸­å¯¦ç¾æ­¤æ¨¡å¼ã€‚

## é€æ­¥å¯¦ç¾

### 1. åŸºæœ¬æ—¥èªŒé…ç½®

æ­¤ç¯„ä¾‹å±•ç¤ºäº†åŸºæœ¬æ—¥èªŒè¨­ç½®å’Œé…ç½®ã€‚

```csharp
// ä½¿ç”¨æ¨¡æ“¬é…ç½®å»ºç«‹æ ¸å¿ƒ
var kernel = Kernel.CreateBuilder().Build();

// å»ºç«‹å•Ÿç”¨æ—¥èªŒçš„å·¥ä½œæµç¨‹
var loggingWorkflow = new GraphExecutor("LoggingWorkflow", "Basic logging configuration", logger);

// é…ç½®æ—¥èªŒé¸é …
var loggingOptions = new GraphLoggingOptions
{
    EnableStructuredLogging = true,
    EnableExecutionLogging = true,
    EnableNodeLogging = true,
    EnablePerformanceLogging = true,
    EnableErrorLogging = true,
    LogLevel = LogLevel.Information,
    EnableLogCorrelation = true,
    EnableLogAggregation = true,
    LogStoragePath = "./logs"
};

loggingWorkflow.ConfigureLogging(loggingOptions);

// å…·æœ‰æ—¥èªŒè¨˜éŒ„çš„ç¯„ä¾‹è™•ç†ç¯€é»
var loggingProcessor = new FunctionGraphNode(
    "logging-processor",
    "Process data with comprehensive logging",
    async (context) =>
    {
        var inputData = context.GetValue<string>("input_data");
        var startTime = DateTime.UtcNow;
        
        // æ—¥èªŒè™•ç†é–‹å§‹
        context.Logger.LogInformation("Starting data processing", new
        {
            NodeId = "logging-processor",
            InputData = inputData,
            StartTime = startTime,
            ExecutionId = context.ExecutionId
        });
        
        // æ¨¡æ“¬è™•ç†
        await Task.Delay(Random.Shared.Next(100, 300));
        
        var processedData = $"Processed: {inputData}";
        var processingTime = DateTime.UtcNow - startTime;
        
        // æ—¥èªŒè™•ç†å®Œæˆ
        context.Logger.LogInformation("Data processing completed", new
        {
            NodeId = "logging-processor",
            InputData = inputData,
            ProcessedData = processedData,
            ProcessingTimeMs = processingTime.TotalMilliseconds,
            ExecutionId = context.ExecutionId
        });
        
        context.SetValue("processed_data", processedData);
        context.SetValue("processing_time_ms", processingTime.TotalMilliseconds);
        context.SetValue("processing_step", "logged_processed");
        
        return processedData;
    });

// æ—¥èªŒèšåˆç¯€é»
var logAggregator = new FunctionGraphNode(
    "log-aggregator",
    "Aggregate and analyze logs",
    async (context) =>
    {
        var processedData = context.GetValue<string>("processed_data");
        var processingTime = context.GetValue<double>("processing_time_ms");
        
        // èšåˆæ—¥èªŒä¿¡æ¯
        var logSummary = new Dictionary<string, object>
        {
            ["total_logs"] = 2, // é–‹å§‹ + å®Œæˆæ—¥èªŒ
            ["processing_time_ms"] = processingTime,
            ["input_data"] = context.GetValue<string>("input_data"),
            ["processed_data"] = processedData,
            ["execution_id"] = context.ExecutionId,
            ["aggregation_timestamp"] = DateTime.UtcNow
        };
        
        context.SetValue("log_summary", logSummary);
        
        // æ—¥èªŒèšåˆå®Œæˆ
        context.Logger.LogInformation("Log aggregation completed", logSummary);
        
        return $"Log aggregation completed: {logSummary["total_logs"]} logs processed";
    });

// å°‡ç¯€é»æ·»åŠ åˆ°å·¥ä½œæµç¨‹
loggingWorkflow.AddNode(loggingProcessor);
loggingWorkflow.AddNode(logAggregator);

// è¨­ç½®èµ·å§‹ç¯€é»
loggingWorkflow.SetStartNode(loggingProcessor.NodeId);

// æ¸¬è©¦åŸºæœ¬æ—¥èªŒ
var testData = new[]
{
    "Sample data 1",
    "Sample data 2",
    "Sample data 3"
};

foreach (var data in testData)
{
    var arguments = new KernelArguments
    {
        ["input_data"] = data
    };

    Console.WriteLine($"ğŸ“ Testing basic logging: {data}");
    var result = await loggingWorkflow.ExecuteAsync(kernel, arguments);
    
    var processingTime = result.GetValue<double>("processing_time_ms");
    var logSummary = result.GetValue<Dictionary<string, object>>("log_summary");
    
    Console.WriteLine($"   Processing Time: {processingTime:F2} ms");
    Console.WriteLine($"   Logs Generated: {logSummary["total_logs"]}");
    Console.WriteLine();
}
```

### 2. é€²éšçµæ§‹åŒ–æ—¥èªŒ

å±•ç¤ºå…·æœ‰èªç¾©ä¿¡æ¯å’Œä¸Šä¸‹æ–‡çš„é€²éšçµæ§‹åŒ–æ—¥èªŒã€‚

```csharp
// å»ºç«‹é€²éšæ—¥èªŒå·¥ä½œæµç¨‹
var advancedLoggingWorkflow = new GraphExecutor("AdvancedLoggingWorkflow", "Advanced structured logging", logger);

// é…ç½®é€²éšæ—¥èªŒ
var advancedLoggingOptions = new GraphLoggingOptions
{
    EnableStructuredLogging = true,
    EnableExecutionLogging = true,
    EnableNodeLogging = true,
    EnablePerformanceLogging = true,
    EnableErrorLogging = true,
    EnableLogCorrelation = true,
    EnableLogAggregation = true,
    EnableSemanticLogging = true,
    EnableContextLogging = true,
    LogLevel = LogLevel.Debug,
    LogStoragePath = "./advanced-logs",
    StructuredLogFormat = "json",
    EnableLogCompression = true,
    MaxLogHistory = 10000
};

advancedLoggingWorkflow.ConfigureLogging(advancedLoggingOptions);

// å…·æœ‰èªç¾©æ—¥èªŒçš„é€²éšè™•ç†ç¯€é»
var advancedProcessor = new FunctionGraphNode(
    "advanced-processor",
    "Advanced processing with semantic logging",
    async (context) =>
    {
        var inputData = context.GetValue<string>("input_data");
        var processingType = context.GetValue<string>("processing_type", "standard");
        var startTime = DateTime.UtcNow;
        
        // å¸¶ä¸Šä¸‹æ–‡çš„èªç¾©æ—¥èªŒ
        context.Logger.LogInformation("Advanced processing initiated", new
        {
            NodeId = "advanced-processor",
            ProcessingType = processingType,
            InputData = inputData,
            StartTime = startTime,
            ExecutionId = context.ExecutionId,
            Context = new
            {
                UserId = context.GetValue<string>("user_id", "anonymous"),
                SessionId = context.GetValue<string>("session_id", "default"),
                RequestId = context.GetValue<string>("request_id", Guid.NewGuid().ToString())
            },
            Metadata = new
            {
                Version = "1.0.0",
                Environment = "development",
                Component = "advanced-processor"
            }
        });
        
        // æ¨¡æ“¬è¤‡é›œè™•ç†
        var iterations = processingType == "complex" ? 1000 : 100;
        var result = 0;
        
        for (int i = 0; i < iterations; i++)
        {
            result += i * i;
            if (i % 100 == 0)
            {
                // é€²åº¦æ—¥èªŒ
                context.Logger.LogDebug("Processing progress", new
                {
                    NodeId = "advanced-processor",
                    Iteration = i,
                    Progress = (double)i / iterations,
                    CurrentResult = result
                });
                
                await Task.Delay(1);
            }
        }
        
        var processingTime = DateTime.UtcNow - startTime;
        var processedData = $"Advanced processed: {inputData} (result: {result})";
        
        // å…·æœ‰æ€§èƒ½æŒ‡æ¨™çš„å®Œæˆæ—¥èªŒ
        context.Logger.LogInformation("Advanced processing completed", new
        {
            NodeId = "advanced-processor",
            ProcessingType = processingType,
            InputData = inputData,
            ProcessedData = processedData,
            ProcessingTimeMs = processingTime.TotalMilliseconds,
            Iterations = iterations,
            FinalResult = result,
            PerformanceMetrics = new
            {
                Throughput = iterations / (processingTime.TotalMilliseconds / 1000.0),
                Efficiency = processingTime.TotalMilliseconds / iterations,
                CpuUsage = GetCurrentCpuUsage(),
                MemoryUsage = GetCurrentMemoryUsage()
            },
            ExecutionId = context.ExecutionId,
            Context = new
            {
                UserId = context.GetValue<string>("user_id", "anonymous"),
                SessionId = context.GetValue<string>("session_id", "default"),
                RequestId = context.GetValue<string>("request_id", Guid.NewGuid().ToString())
            }
        });
        
        context.SetValue("processed_data", processedData);
        context.SetValue("processing_time_ms", processingTime.TotalMilliseconds);
        context.SetValue("iterations", iterations);
        context.SetValue("final_result", result);
        context.SetValue("processing_step", "advanced_logged_processed");
        
        return processedData;
    });

// èªç¾©æ—¥èªŒåˆ†æå™¨
var semanticLogAnalyzer = new FunctionGraphNode(
    "semantic-log-analyzer",
    "Analyze semantic logs and extract insights",
    async (context) =>
    {
        var processedData = context.GetValue<string>("processed_data");
        var processingTime = context.GetValue<double>("processing_time_ms");
        var iterations = context.GetValue<int>("iterations");
        var finalResult = context.GetValue<int>("final_result");
        
        // åˆ†ææ—¥èªŒæ¨¡å¼ä¸¦æå–æ´å¯Ÿ
        var logAnalysis = new Dictionary<string, object>
        {
            ["processing_summary"] = new
            {
                TotalTime = processingTime,
                Iterations = iterations,
                FinalResult = finalResult,
                Throughput = iterations / (processingTime / 1000.0)
            },
            ["performance_insights"] = new
            {
                IsEfficient = processingTime < 1000, // å°‘æ–¼ 1 ç§’
                Complexity = iterations > 500 ? "high" : "medium",
                OptimizationOpportunity = processingTime > 500 ? "yes" : "no"
            },
            ["semantic_patterns"] = new
            {
                ProcessingType = context.GetValue<string>("processing_type"),
                UserContext = context.GetValue<string>("user_id"),
                SessionContext = context.GetValue<string>("session_id")
            },
            ["analysis_timestamp"] = DateTime.UtcNow,
            ["execution_id"] = context.ExecutionId
        };
        
        context.SetValue("log_analysis", logAnalysis);
        
        // æ—¥èªŒåˆ†æå®Œæˆ
        context.Logger.LogInformation("Semantic log analysis completed", logAnalysis);
        
        return $"Semantic log analysis completed with {logAnalysis.Count} insights";
    });

// å°‡ç¯€é»æ·»åŠ åˆ°é€²éšå·¥ä½œæµç¨‹
advancedLoggingWorkflow.AddNode(advancedProcessor);
advancedLoggingWorkflow.AddNode(semanticLogAnalyzer);

// è¨­ç½®èµ·å§‹ç¯€é»
advancedLoggingWorkflow.SetStartNode(advancedProcessor.NodeId);

// æ¸¬è©¦é€²éšæ—¥èªŒ
var advancedTestScenarios = new[]
{
    new { Data = "Simple processing", Type = "simple" },
    new { Data = "Complex processing", Type = "complex" },
    new { Data = "Standard processing", Type = "standard" }
};

foreach (var scenario in advancedTestScenarios)
{
    var arguments = new KernelArguments
    {
        ["input_data"] = scenario.Data,
        ["processing_type"] = scenario.Type,
        ["user_id"] = "user123",
        ["session_id"] = "session456",
        ["request_id"] = Guid.NewGuid().ToString()
    };

    Console.WriteLine($"ğŸ” Testing advanced logging: {scenario.Data}");
    Console.WriteLine($"   Processing Type: {scenario.Type}");
    
    var result = await advancedLoggingWorkflow.ExecuteAsync(kernel, arguments);
    
    var processingTime = result.GetValue<double>("processing_time_ms");
    var iterations = result.GetValue<int>("iterations");
    var logAnalysis = result.GetValue<Dictionary<string, object>>("log_analysis");
    
    Console.WriteLine($"   Processing Time: {processingTime:F2} ms");
    Console.WriteLine($"   Iterations: {iterations:N0}");
    Console.WriteLine($"   Insights Generated: {logAnalysis.Count}");
    Console.WriteLine();
}
```

### 3. éŒ¯èª¤æ—¥èªŒå’Œç›£æ§

å±•ç¤ºå¦‚ä½•å¯¦ç¾å…¨é¢çš„éŒ¯èª¤æ—¥èªŒå’Œç›£æ§ã€‚

```csharp
// å»ºç«‹éŒ¯èª¤æ—¥èªŒå·¥ä½œæµç¨‹
var errorLoggingWorkflow = new GraphExecutor("ErrorLoggingWorkflow", "Error logging and monitoring", logger);

// é…ç½®éŒ¯èª¤æ—¥èªŒ
var errorLoggingOptions = new GraphLoggingOptions
{
    EnableStructuredLogging = true,
    EnableExecutionLogging = true,
    EnableNodeLogging = true,
    EnableErrorLogging = true,
    EnableErrorAggregation = true,
    EnableErrorCorrelation = true,
    EnableErrorReporting = true,
    LogLevel = LogLevel.Warning,
    LogStoragePath = "./error-logs",
    ErrorLogRetention = TimeSpan.FromDays(30),
    EnableErrorMetrics = true
};

errorLoggingWorkflow.ConfigureLogging(errorLoggingOptions);

// å®¹æ˜“å‡ºéŒ¯çš„è™•ç†ç¯€é»
var errorProneProcessor = new FunctionGraphNode(
    "error-prone-processor",
    "Process data with potential errors",
    async (context) =>
    {
        var inputData = context.GetValue<string>("input_data");
        var errorProbability = context.GetValue<double>("error_probability", 0.3);
        var startTime = DateTime.UtcNow;
        
        try
        {
            // æ—¥èªŒè™•ç†é–‹å§‹
            context.Logger.LogInformation("Error-prone processing started", new
            {
                NodeId = "error-prone-processor",
                InputData = inputData,
                ErrorProbability = errorProbability,
                StartTime = startTime,
                ExecutionId = context.ExecutionId
            });
            
            // æ¨¡æ“¬å¯èƒ½å‡ºéŒ¯çš„è™•ç†
            var random = Random.Shared.NextDouble();
            if (random < errorProbability)
            {
                // æ¨¡æ“¬éŒ¯èª¤
                var errorMessage = $"Processing failed for input: {inputData}";
                var exception = new InvalidOperationException(errorMessage);
                
                // å¸¶ä¸Šä¸‹æ–‡è¨˜éŒ„éŒ¯èª¤
                context.Logger.LogError(exception, "Processing error occurred", new
                {
                    NodeId = "error-prone-processor",
                    InputData = inputData,
                    ErrorType = exception.GetType().Name,
                    ErrorMessage = errorMessage,
                    ErrorProbability = errorProbability,
                    RandomValue = random,
                    ProcessingTimeMs = (DateTime.UtcNow - startTime).TotalMilliseconds,
                    ExecutionId = context.ExecutionId,
                    Context = new
                    {
                        UserId = context.GetValue<string>("user_id", "anonymous"),
                        SessionId = context.GetValue<string>("session_id", "default"),
                        RequestId = context.GetValue<string>("request_id", Guid.NewGuid().ToString())
                    }
                });
                
                // è¨­ç½®éŒ¯èª¤ç‹€æ…‹
                context.SetValue("error_occurred", true);
                context.SetValue("error_message", errorMessage);
                context.SetValue("error_type", exception.GetType().Name);
                context.SetValue("processing_step", "error_logged");
                
                throw exception;
            }
            
            // æˆåŠŸè™•ç†
            await Task.Delay(Random.Shared.Next(100, 300));
            var processedData = $"Successfully processed: {inputData}";
            var processingTime = DateTime.UtcNow - startTime;
            
            // æ—¥èªŒæˆåŠŸ
            context.Logger.LogInformation("Processing completed successfully", new
            {
                NodeId = "error-prone-processor",
                InputData = inputData,
                ProcessedData = processedData,
                ProcessingTimeMs = processingTime.TotalMilliseconds,
                ErrorProbability = errorProbability,
                RandomValue = random,
                ExecutionId = context.ExecutionId
            });
            
            context.SetValue("processed_data", processedData);
            context.SetValue("processing_time_ms", processingTime.TotalMilliseconds);
            context.SetValue("error_occurred", false);
            context.SetValue("processing_step", "success_logged");
            
            return processedData;
        }
        catch (Exception ex)
        {
            // æœªè™•ç†ä¾‹å¤–çš„é¡å¤–éŒ¯èª¤æ—¥èªŒ
            context.Logger.LogCritical(ex, "Unhandled exception in error-prone processor", new
            {
                NodeId = "error-prone-processor",
                InputData = inputData,
                ExceptionType = ex.GetType().Name,
                ExceptionMessage = ex.Message,
                StackTrace = ex.StackTrace,
                ExecutionId = context.ExecutionId
            });
            
            throw;
        }
    });

// éŒ¯èª¤ç›£æ§å’Œèšåˆå™¨
var errorMonitor = new FunctionGraphNode(
    "error-monitor",
    "Monitor and aggregate error logs",
    async (context) =>
    {
        var errorOccurred = context.GetValue<bool>("error_occurred", false);
        var errorMessage = context.GetValue<string>("error_message", "");
        var errorType = context.GetValue<string>("error_type", "");
        var processingTime = context.GetValue<double>("processing_time_ms", 0.0);
        
        // èšåˆéŒ¯èª¤ä¿¡æ¯
        var errorSummary = new Dictionary<string, object>
        {
            ["error_summary"] = new
            {
                ErrorOccurred = errorOccurred,
                ErrorMessage = errorMessage,
                ErrorType = errorType,
                ProcessingTimeMs = processingTime,
                Timestamp = DateTime.UtcNow
            },
            ["execution_metrics"] = new
            {
                TotalExecutions = 1,
                SuccessfulExecutions = errorOccurred ? 0 : 1,
                FailedExecutions = errorOccurred ? 1 : 0,
                SuccessRate = errorOccurred ? 0.0 : 1.0,
                AverageProcessingTime = processingTime
            },
            ["monitoring_data"] = new
            {
                ExecutionId = context.ExecutionId,
                NodeId = "error-prone-processor",
                MonitoringTimestamp = DateTime.UtcNow,
                AlertLevel = errorOccurred ? "warning" : "info"
            }
        };
        
        context.SetValue("error_summary", errorSummary);
        
        // æ—¥èªŒç›£æ§çµæœ
        if (errorOccurred)
        {
            context.Logger.LogWarning("Error monitoring alert", errorSummary);
        }
        else
        {
            context.Logger.LogInformation("Error monitoring completed", errorSummary);
        }
        
        return $"Error monitoring completed. Errors: {(errorOccurred ? 1 : 0)}";
    });

// å°‡ç¯€é»æ·»åŠ åˆ°éŒ¯èª¤å·¥ä½œæµç¨‹
errorLoggingWorkflow.AddNode(errorProneProcessor);
errorLoggingWorkflow.AddNode(errorMonitor);

// è¨­ç½®èµ·å§‹ç¯€é»
errorLoggingWorkflow.SetStartNode(errorProneProcessor.NodeId);

// æ¸¬è©¦éŒ¯èª¤æ—¥èªŒ
var errorTestScenarios = new[]
{
    new { Data = "Low error probability", Probability = 0.1 },
    new { Data = "Medium error probability", Probability = 0.5 },
    new { Data = "High error probability", Probability = 0.8 }
};

foreach (var scenario in errorTestScenarios)
{
    var arguments = new KernelArguments
    {
        ["input_data"] = scenario.Data,
        ["error_probability"] = scenario.Probability,
        ["user_id"] = "user123",
        ["session_id"] = "session456",
        ["request_id"] = Guid.NewGuid().ToString()
    };

    Console.WriteLine($"âš ï¸ Testing error logging: {scenario.Data}");
    Console.WriteLine($"   Error Probability: {scenario.Probability:P0}");
    
    try
    {
        var result = await errorLoggingWorkflow.ExecuteAsync(kernel, arguments);
        
        var errorOccurred = result.GetValue<bool>("error_occurred");
        var processingStep = result.GetValue<string>("processing_step");
        var errorSummary = result.GetValue<Dictionary<string, object>>("error_summary");
        
        Console.WriteLine($"   Error Occurred: {errorOccurred}");
        Console.WriteLine($"   Processing Step: {processingStep}");
        Console.WriteLine($"   Monitoring Data: {errorSummary.Count} metrics");
    }
    catch (Exception ex)
    {
        Console.WriteLine($"   Exception Caught: {ex.GetType().Name}: {ex.Message}");
    }
    
    Console.WriteLine();
}
```

### 4. æ—¥èªŒåŒ¯å‡ºå’Œæ•´åˆ

å±•ç¤ºå°‡æ—¥èªŒåŒ¯å‡ºåˆ°å¤–éƒ¨ç³»çµ±ä¸¦èˆ‡ç›£æ§å¹³å°æ•´åˆã€‚

```csharp
// å»ºç«‹æ—¥èªŒåŒ¯å‡ºå·¥ä½œæµç¨‹
var logExportWorkflow = new GraphExecutor("LogExportWorkflow", "Log export and integration", logger);

// é…ç½®æ—¥èªŒåŒ¯å‡º
var logExportOptions = new GraphLoggingOptions
{
    EnableStructuredLogging = true,
    EnableExecutionLogging = true,
    EnableNodeLogging = true,
    EnableLogExport = true,
    EnableLogPersistence = true,
    EnableLogCompression = true,
    LogStoragePath = "./export-logs",
    ExportFormats = new[] { "json", "csv", "logstash", "fluentd" },
    ExportInterval = TimeSpan.FromSeconds(5),
    EnableLogRotation = true,
    MaxLogFileSize = 10 * 1024 * 1024, // 10MB
    LogRetentionDays = 7
};

logExportWorkflow.ConfigureLogging(logExportOptions);

// æ—¥èªŒç”Ÿæˆå™¨
var logGenerator = new FunctionGraphNode(
    "log-generator",
    "Generate sample logs for export",
    async (context) =>
    {
        var iteration = context.GetValue<int>("iteration", 0);
        var logCount = context.GetValue<int>("log_count", 10);
        
        // ç”Ÿæˆå„ç¨®æ—¥èªŒé¡å‹
        var logs = new List<Dictionary<string, object>>();
        
        for (int i = 0; i < logCount; i++)
        {
            var logEntry = new Dictionary<string, object>
            {
                ["timestamp"] = DateTime.UtcNow.AddSeconds(-i),
                ["level"] = GetRandomLogLevel(),
                ["message"] = $"Sample log message {iteration}-{i}",
                ["node_id"] = "log-generator",
                ["execution_id"] = context.ExecutionId,
                ["iteration"] = iteration,
                ["log_index"] = i,
                ["metadata"] = new
                {
                    Source = "log-generator",
                    Version = "1.0.0",
                    Environment = "development"
                }
            };
            
            logs.Add(logEntry);
        }
        
        context.SetValue("generated_logs", logs);
        context.SetValue("log_count", logs.Count);
        context.SetValue("generation_timestamp", DateTime.UtcNow);
        
        // æ—¥èªŒç”Ÿæˆå®Œæˆ
        context.Logger.LogInformation("Log generation completed", new
        {
            NodeId = "log-generator",
            LogCount = logs.Count,
            Iteration = iteration,
            ExecutionId = context.ExecutionId
        });
        
        return $"Generated {logs.Count} log entries for iteration {iteration}";
    });

// æ—¥èªŒåŒ¯å‡ºå™¨
var logExporter = new FunctionGraphNode(
    "log-exporter",
    "Export logs to external systems",
    async (context) =>
    {
        var generatedLogs = context.GetValue<List<Dictionary<string, object>>>("generated_logs");
        var iteration = context.GetValue<int>("iteration");
        var generationTimestamp = context.GetValue<DateTime>("generation_timestamp");
        
        // åŒ¯å‡ºåˆ°ä¸åŒæ ¼å¼
        var exportResults = new Dictionary<string, string>();
        
        // JSON åŒ¯å‡º
        var jsonExport = await ExportLogsToJson(generatedLogs);
        exportResults["json"] = jsonExport;
        
        // CSV åŒ¯å‡º
        var csvExport = await ExportLogsToCsv(generatedLogs);
        exportResults["csv"] = csvExport;
        
        // Logstash åŒ¯å‡º
        var logstashExport = await ExportLogsToLogstash(generatedLogs);
        exportResults["logstash"] = logstashExport;
        
        // Fluentd åŒ¯å‡º
        var fluentdExport = await ExportLogsToFluentd(generatedLogs);
        exportResults["fluentd"] = fluentdExport;
        
        // åŒ¯å‡ºåˆ°ç›£æ§ç³»çµ±
        var monitoringExport = await ExportLogsToMonitoring(generatedLogs);
        exportResults["monitoring"] = monitoringExport;
        
        // å»ºç«‹åŒ¯å‡ºæ‘˜è¦
        var exportSummary = new Dictionary<string, object>
        {
            ["export_summary"] = new
            {
                TotalLogs = generatedLogs.Count,
                ExportFormats = exportResults.Count,
                ExportFormatsList = exportResults.Keys.ToArray(),
                Iteration = iteration,
                GenerationTimestamp = generationTimestamp,
                ExportTimestamp = DateTime.UtcNow
            },
            ["export_results"] = exportResults,
            ["export_metadata"] = new
            {
                ExportPath = "./export-logs",
                CompressionEnabled = true,
                RotationEnabled = true,
                RetentionDays = 7
            }
        };
        
        context.SetValue("export_summary", exportSummary);
        
        // æ—¥èªŒåŒ¯å‡ºå®Œæˆ
        context.Logger.LogInformation("Log export completed", exportSummary);
        
        return $"Logs exported to {exportResults.Count} formats";
    });

// å°‡ç¯€é»æ·»åŠ åˆ°åŒ¯å‡ºå·¥ä½œæµç¨‹
logExportWorkflow.AddNode(logGenerator);
logExportWorkflow.AddNode(logExporter);

// è¨­ç½®èµ·å§‹ç¯€é»
logExportWorkflow.SetStartNode(logGenerator.NodeId);

// æ¸¬è©¦æ—¥èªŒåŒ¯å‡º
Console.WriteLine("ğŸ“¤ Testing log export and integration...");

var exportArguments = new KernelArguments
{
    ["iteration"] = 1,
    ["log_count"] = 25
};

var result = await logExportWorkflow.ExecuteAsync(kernel, exportArguments);

var exportSummary = result.GetValue<Dictionary<string, object>>("export_summary");
var generatedLogs = result.GetValue<List<Dictionary<string, object>>>("generated_logs");

if (exportSummary != null)
{
    var summary = exportSummary["export_summary"] as dynamic;
    Console.WriteLine($"   Total Logs: {summary.TotalLogs}");
    Console.WriteLine($"   Export Formats: {string.Join(", ", summary.ExportFormatsList)}");
    Console.WriteLine($"   Export Path: {exportSummary["export_metadata"].ExportPath}");
}

Console.WriteLine("âœ… Log export testing completed");

// æ—¥èªŒåŒ¯å‡ºçš„è¼”åŠ©æ–¹æ³•
async Task<string> ExportLogsToJson(List<Dictionary<string, object>> logs)
{
    var json = System.Text.Json.JsonSerializer.Serialize(logs, new System.Text.Json.JsonSerializerOptions
    {
        WriteIndented = true
    });
    
    var filename = $"./export-logs/logs_{DateTime.UtcNow:yyyyMMdd_HHmmss}.json";
    await File.WriteAllTextAsync(filename, json);
    
    return filename;
}

async Task<string> ExportLogsToCsv(List<Dictionary<string, object>> logs)
{
    var csv = new StringBuilder();
    
    if (logs.Any())
    {
        // æ¨™é¡Œ
        var headers = logs.First().Keys;
        csv.AppendLine(string.Join(",", headers));
        
        // æ•¸æ“š
        foreach (var log in logs)
        {
            var values = headers.Select(h => log[h]?.ToString() ?? "").Select(v => $"\"{v}\"");
            csv.AppendLine(string.Join(",", values));
        }
    }
    
    var filename = $"./export-logs/logs_{DateTime.UtcNow:yyyyMMdd_HHmmss}.csv";
    await File.WriteAllTextAsync(filename, csv.ToString());
    
    return filename;
}

async Task<string> ExportLogsToLogstash(List<Dictionary<string, object>> logs)
{
    var logstashFormat = new StringBuilder();
    
    foreach (var log in logs)
    {
        var logstashEntry = new
        {
            @timestamp = log["timestamp"],
            level = log["level"],
            message = log["message"],
            node_id = log["node_id"],
            execution_id = log["execution_id"],
            metadata = log["metadata"]
        };
        
        logstashFormat.AppendLine(System.Text.Json.JsonSerializer.Serialize(logstashEntry));
    }
    
    var filename = $"./export-logs/logs_{DateTime.UtcNow:yyyyMMdd_HHmmss}.logstash";
    await File.WriteAllTextAsync(filename, logstashFormat.ToString());
    
    return filename;
}

async Task<string> ExportLogsToFluentd(List<Dictionary<string, object>> logs)
{
    var fluentdFormat = new StringBuilder();
    
    foreach (var log in logs)
    {
        var fluentdEntry = new
        {
            time = log["timestamp"],
            level = log["level"],
            message = log["message"],
            node_id = log["node_id"],
            execution_id = log["execution_id"],
            metadata = log["metadata"]
        };
        
        fluentdFormat.AppendLine(System.Text.Json.JsonSerializer.Serialize(fluentdEntry));
    }
    
    var filename = $"./export-logs/logs_{DateTime.UtcNow:yyyyMMdd_HHmmss}.fluentd";
    await File.WriteAllTextAsync(filename, fluentdFormat.ToString());
    
    return filename;
}

async Task<string> ExportLogsToMonitoring(List<Dictionary<string, object>> logs)
{
    // æ¨¡æ“¬åŒ¯å‡ºåˆ°ç›£æ§ç³»çµ±
    var monitoringData = new
    {
        source = "semantic-kernel-graph",
        timestamp = DateTime.UtcNow,
        log_count = logs.Count,
        log_levels = logs.GroupBy(l => l["level"]).ToDictionary(g => g.Key, g => g.Count()),
        execution_ids = logs.Select(l => l["execution_id"]).Distinct().ToArray()
    };
    
    var filename = $"./export-logs/monitoring_{DateTime.UtcNow:yyyyMMdd_HHmmss}.json";
    await File.WriteAllTextAsync(filename, System.Text.Json.JsonSerializer.Serialize(monitoringData, new System.Text.Json.JsonSerializerOptions
    {
        WriteIndented = true
    }));
    
    return filename;
}

string GetRandomLogLevel()
{
    var levels = new[] { "Debug", "Information", "Warning", "Error" };
    var weights = new[] { 0.4, 0.4, 0.15, 0.05 }; // 40% Debugã€40% Infoã€15% Warningã€5% Error
    
    var random = Random.Shared.NextDouble();
    var cumulativeWeight = 0.0;
    
    for (int i = 0; i < levels.Length; i++)
    {
        cumulativeWeight += weights[i];
        if (random <= cumulativeWeight)
        {
            return levels[i];
        }
    }
    
    return levels[0];
}
```

## é æœŸè¼¸å‡º

### åŸºæœ¬æ—¥èªŒé…ç½®ç¯„ä¾‹

```
ğŸ“ Testing basic logging: Sample data 1
   Processing Time: 234.56 ms
   Logs Generated: 2

ğŸ“ Testing basic logging: Sample data 2
   Processing Time: 187.23 ms
   Logs Generated: 2
```

### é€²éšçµæ§‹åŒ–æ—¥èªŒç¯„ä¾‹

```
ğŸ” Testing advanced logging: Simple processing
   Processing Type: simple
   Processing Time: 156.78 ms
   Iterations: 100
   Insights Generated: 4

ğŸ” Testing advanced logging: Complex processing
   Processing Type: complex
   Processing Time: 1,234.56 ms
   Iterations: 1,000
   Insights Generated: 4
```

### éŒ¯èª¤æ—¥èªŒå’Œç›£æ§ç¯„ä¾‹

```
âš ï¸ Testing error logging: Low error probability
   Error Probability: 10%
   Error Occurred: False
   Processing Step: success_logged
   Monitoring Data: 3 metrics

âš ï¸ Testing error logging: High error probability
   Error Probability: 80%
   Error Occurred: True
   Processing Step: error_logged
   Monitoring Data: 3 metrics
```

### æ—¥èªŒåŒ¯å‡ºå’Œæ•´åˆç¯„ä¾‹

```
ğŸ“¤ Testing log export and integration...
   Total Logs: 25
   Export Formats: json, csv, logstash, fluentd, monitoring
   Export Path: ./export-logs
âœ… Log export testing completed
```

## é…ç½®é¸é …

### æ—¥èªŒé…ç½®

```csharp
var loggingOptions = new GraphLoggingOptions
{
    EnableStructuredLogging = true,                    // å•Ÿç”¨çµæ§‹åŒ–æ—¥èªŒ
    EnableExecutionLogging = true,                     // å•Ÿç”¨åŸ·è¡Œç´šæ—¥èªŒ
    EnableNodeLogging = true,                          // å•Ÿç”¨ç¯€é»ç´šæ—¥èªŒ
    EnablePerformanceLogging = true,                   // å•Ÿç”¨æ€§èƒ½æ—¥èªŒ
    EnableErrorLogging = true,                         // å•Ÿç”¨éŒ¯èª¤æ—¥èªŒ
    EnableErrorAggregation = true,                     // å•Ÿç”¨éŒ¯èª¤èšåˆ
    EnableErrorCorrelation = true,                     // å•Ÿç”¨éŒ¯èª¤é—œè¯
    EnableErrorReporting = true,                       // å•Ÿç”¨éŒ¯èª¤å ±å‘Š
    EnableSemanticLogging = true,                      // å•Ÿç”¨èªç¾©æ—¥èªŒ
    EnableContextLogging = true,                       // å•Ÿç”¨ä¸Šä¸‹æ–‡æ—¥èªŒ
    EnableLogCorrelation = true,                       // å•Ÿç”¨æ—¥èªŒé—œè¯
    EnableLogAggregation = true,                       // å•Ÿç”¨æ—¥èªŒèšåˆ
    EnableLogExport = true,                            // å•Ÿç”¨æ—¥èªŒåŒ¯å‡º
    EnableLogPersistence = true,                       // å•Ÿç”¨æ—¥èªŒæŒä¹…åŒ–
    EnableLogCompression = true,                       // å•Ÿç”¨æ—¥èªŒå£“ç¸®
    EnableLogRotation = true,                          // å•Ÿç”¨æ—¥èªŒè¼ªæ›
    EnableErrorMetrics = true,                         // å•Ÿç”¨éŒ¯èª¤æŒ‡æ¨™
    LogLevel = LogLevel.Information,                   // é è¨­æ—¥èªŒç´šåˆ¥
    StructuredLogFormat = "json",                      // çµæ§‹åŒ–æ—¥èªŒæ ¼å¼
    LogStoragePath = "./logs",                         // æ—¥èªŒå„²å­˜è·¯å¾‘
    ExportFormats = new[] { "json", "csv", "logstash", "fluentd" }, // åŒ¯å‡ºæ ¼å¼
    ExportInterval = TimeSpan.FromSeconds(5),          // åŒ¯å‡ºé–“éš”
    MaxLogFileSize = 10 * 1024 * 1024,                // æœ€å¤§æ—¥èªŒæ–‡ä»¶å¤§å° (10MB)
    LogRetentionDays = 7,                              // æ—¥èªŒä¿ç•™æœŸé™
    ErrorLogRetention = TimeSpan.FromDays(30),         // éŒ¯èª¤æ—¥èªŒä¿ç•™æœŸé™
    MaxLogHistory = 10000,                             // æœ€å¤§æ—¥èªŒæ­·å²
    EnableLogCompression = true,                       // å•Ÿç”¨æ—¥èªŒå£“ç¸®
    CompressionLevel = System.IO.Compression.CompressionLevel.Optimal // å£“ç¸®ç´šåˆ¥
};
```

### éŒ¯èª¤æ—¥èªŒé…ç½®

```csharp
var errorLoggingOptions = new ErrorLoggingOptions
{
    EnableErrorAggregation = true,                     // å•Ÿç”¨éŒ¯èª¤èšåˆ
    EnableErrorCorrelation = true,                     // å•Ÿç”¨éŒ¯èª¤é—œè¯
    EnableErrorReporting = true,                       // å•Ÿç”¨éŒ¯èª¤å ±å‘Š
    EnableErrorMetrics = true,                         // å•Ÿç”¨éŒ¯èª¤æŒ‡æ¨™
    EnableErrorAlerts = true,                          // å•Ÿç”¨éŒ¯èª¤è­¦å ±
    EnableErrorTrends = true,                          // å•Ÿç”¨éŒ¯èª¤è¶¨å‹¢åˆ†æ
    ErrorLogRetention = TimeSpan.FromDays(30),         // éŒ¯èª¤æ—¥èªŒä¿ç•™æœŸé™
    MaxErrorHistory = 1000,                            // æœ€å¤§éŒ¯èª¤æ­·å²
    ErrorAlertThreshold = 5,                           // éŒ¯èª¤è­¦å ±é–¾å€¼
    ErrorAlertWindow = TimeSpan.FromMinutes(5),        // éŒ¯èª¤è­¦å ±çª—å£
    EnableErrorSampling = true,                        // å•Ÿç”¨éŒ¯èª¤æ¡æ¨£
    ErrorSamplingRate = 0.1,                           // éŒ¯èª¤æ¡æ¨£ç‡ (10%)
    EnableErrorDeduplication = true,                   // å•Ÿç”¨éŒ¯èª¤å»é‡
    ErrorDeduplicationWindow = TimeSpan.FromMinutes(10) // éŒ¯èª¤å»é‡çª—å£
};
```

## æ•…éšœæ’é™¤

### å¸¸è¦‹å•é¡Œ

#### æœªç”Ÿæˆæ—¥èªŒ
```bash
# å•é¡Œï¼šæœªç”Ÿæˆæ—¥èªŒ
# è§£æ±ºæ–¹æ¡ˆï¼šæª¢æŸ¥æ—¥èªŒé…ç½®ä¸¦å•Ÿç”¨æ‰€éœ€åŠŸèƒ½
EnableStructuredLogging = true;
EnableExecutionLogging = true;
LogLevel = LogLevel.Information;
```

#### æ€§èƒ½å½±éŸ¿
```bash
# å•é¡Œï¼šæ—¥èªŒè¨˜éŒ„å½±éŸ¿æ€§èƒ½
# è§£æ±ºæ–¹æ¡ˆï¼šèª¿æ•´æ—¥èªŒç´šåˆ¥ä¸¦å•Ÿç”¨å£“ç¸®
LogLevel = LogLevel.Warning;
EnableLogCompression = true;
EnableLogSampling = true;
```

#### å„²å­˜å•é¡Œ
```bash
# å•é¡Œï¼šæ—¥èªŒæ¶ˆè€—å¤§é‡å„²å­˜ç©ºé–“
# è§£æ±ºæ–¹æ¡ˆï¼šå•Ÿç”¨è¼ªæ›ä¸¦è¨­ç½®ä¿ç•™æ”¿ç­–
EnableLogRotation = true;
MaxLogFileSize = 5 * 1024 * 1024; // 5MB
LogRetentionDays = 3;
```

### èª¿è©¦æ¨¡å¼

å•Ÿç”¨è©³ç´°æ—¥èªŒè¨˜éŒ„ä»¥é€²è¡Œæ•…éšœæ’é™¤ï¼š

```csharp
// å•Ÿç”¨èª¿è©¦æ—¥èªŒ
var logger = LoggerFactory.Create(builder =>
{
    builder.AddConsole();
    builder.SetMinimumLevel(LogLevel.Debug);
}).CreateLogger<LoggingExample>();

// ä½¿ç”¨èª¿è©¦æ—¥èªŒé…ç½®æ—¥èªŒ
var debugLoggingOptions = new GraphLoggingOptions
{
    EnableStructuredLogging = true,
    EnableExecutionLogging = true,
    EnableNodeLogging = true,
    EnableDebugLogging = true,
    LogLevel = LogLevel.Debug,
    LogVisualizationUpdates = true,
    LogExportOperations = true
};
```

## é€²éšæ¨¡å¼

### è‡ªè¨‚æ—¥èªŒæ ¼å¼åŒ–ç¨‹å¼

```csharp
// å¯¦ç¾è‡ªè¨‚æ—¥èªŒæ ¼å¼åŒ–ç¨‹å¼
public class CustomLogFormatter : ILogFormatter
{
    public async Task<string> FormatLogAsync(LogEntry entry, Dictionary<string, object> context)
    {
        var customFormat = new StringBuilder();
        
        // è‡ªè¨‚æ¨™é¡Œ
        customFormat.AppendLine("=== CUSTOM LOG ENTRY ===");
        customFormat.AppendLine($"Timestamp: {entry.Timestamp:yyyy-MM-dd HH:mm:ss.fff}");
        customFormat.AppendLine($"Level: {entry.Level}");
        customFormat.AppendLine($"Message: {entry.Message}");
        customFormat.AppendLine($"Node: {entry.NodeId}");
        customFormat.AppendLine($"Execution: {entry.ExecutionId}");
        
        // è‡ªè¨‚ä¸Šä¸‹æ–‡æ ¼å¼åŒ–
        if (context.Any())
        {
            customFormat.AppendLine("Context:");
            foreach (var kvp in context)
            {
                customFormat.AppendLine($"  {kvp.Key}: {kvp.Value}");
            }
        }
        
        customFormat.AppendLine("========================");
        
        return customFormat.ToString();
    }
}
```

### è‡ªè¨‚æ—¥èªŒèšåˆå™¨

```csharp
// å¯¦ç¾è‡ªè¨‚æ—¥èªŒèšåˆå™¨
public class CustomLogAggregator : ILogAggregator
{
    public async Task<LogAggregationResult> AggregateLogsAsync(IEnumerable<LogEntry> logs)
    {
        var aggregation = new LogAggregationResult();
        
        foreach (var log in logs)
        {
            // æŒ‰ç´šåˆ¥èšåˆ
            if (!aggregation.LevelCounts.ContainsKey(log.Level))
                aggregation.LevelCounts[log.Level] = 0;
            aggregation.LevelCounts[log.Level]++;
            
            // æŒ‰ç¯€é»èšåˆ
            if (!aggregation.NodeCounts.ContainsKey(log.NodeId))
                aggregation.NodeCounts[log.NodeId] = 0;
            aggregation.NodeCounts[log.NodeId]++;
            
            // è¿½è¹¤åŸ·è¡Œæ¨¡å¼
            if (!aggregation.ExecutionPatterns.ContainsKey(log.ExecutionId))
                aggregation.ExecutionPatterns[log.ExecutionId] = new List<LogEntry>();
            aggregation.ExecutionPatterns[log.ExecutionId].Add(log);
        }
        
        // è¨ˆç®—è¡ç”ŸæŒ‡æ¨™
        aggregation.TotalLogs = logs.Count();
        aggregation.AverageLogsPerExecution = aggregation.ExecutionPatterns.Count > 0 
            ? (double)aggregation.TotalLogs / aggregation.ExecutionPatterns.Count 
            : 0;
        
        return aggregation;
    }
}
```

### å³æ™‚æ—¥èªŒç›£æ§

```csharp
// å¯¦ç¾å³æ™‚æ—¥èªŒç›£æ§
public class RealTimeLogMonitor : ILogMonitor
{
    private readonly List<LogEntry> _recentLogs = new();
    private readonly object _lock = new();
    
    public async Task MonitorLogAsync(LogEntry entry)
    {
        lock (_lock)
        {
            _recentLogs.Add(entry);
            
            // åƒ…ä¿ç•™æœ€è¿‘çš„æ—¥èªŒ (æœ€å¾Œ 1000 æ¢)
            if (_recentLogs.Count > 1000)
            {
                _recentLogs.RemoveRange(0, _recentLogs.Count - 1000);
            }
        }
        
        // æª¢æŸ¥è­¦å ±
        await CheckAlertsAsync(entry);
    }
    
    private async Task CheckAlertsAsync(LogEntry entry)
    {
        // æª¢æŸ¥éŒ¯èª¤ç‡è­¦å ±
        var recentErrors = _recentLogs
            .Where(l => l.Level == LogLevel.Error)
            .Where(l => l.Timestamp > DateTime.UtcNow.AddMinutes(-5))
            .Count();
        
        if (recentErrors > 10)
        {
            await SendAlertAsync($"High error rate detected: {recentErrors} errors in last 5 minutes");
        }
        
        // æª¢æŸ¥ç‰¹å®šéŒ¯èª¤æ¨¡å¼
        if (entry.Level == LogLevel.Error && entry.Message.Contains("critical"))
        {
            await SendAlertAsync($"Critical error detected: {entry.Message}");
        }
    }
    
    private async Task SendAlertAsync(string message)
    {
        // è­¦å ±ç™¼é€å¯¦ç¾
        Console.WriteLine($"ğŸš¨ ALERT: {message}");
        await Task.CompletedTask;
    }
}
```

## ç›¸é—œç¯„ä¾‹

* [åœ–å½¢æŒ‡æ¨™](./graph-metrics.md)ï¼šæŒ‡æ¨™æ”¶é›†å’Œç›£æ§
* [åœ–å½¢å¯è¦–åŒ–](./graph-visualization.md)ï¼šæ—¥èªŒçš„è¦–è¦ºè¡¨ç¤º
* [èª¿è©¦å’Œæª¢æŸ¥](./debug-inspection.md)ï¼šä½¿ç”¨æ—¥èªŒé€²è¡Œèª¿è©¦
* [æ€§èƒ½æœ€ä½³åŒ–](./performance-optimization.md)ï¼šåŸºæ–¼æ—¥èªŒçš„æ€§èƒ½åˆ†æ

## å¦è«‹åƒé–±

* [æ—¥èªŒè¨˜éŒ„å’Œå¯è§€æ¸¬æ€§](../concepts/logging.md)ï¼šäº†è§£æ—¥èªŒæ¦‚å¿µ
* [èª¿è©¦å’Œæª¢æŸ¥](../how-to/debug-and-inspection.md)ï¼šä½¿ç”¨æ—¥èªŒé€²è¡Œèª¿è©¦
* [æ€§èƒ½ç›£æ§](../how-to/performance-monitoring.md)ï¼šæ€§èƒ½æ—¥èªŒè¨˜éŒ„
* [API åƒè€ƒ](../api/)ï¼šå®Œæ•´çš„ API æ–‡æª”
