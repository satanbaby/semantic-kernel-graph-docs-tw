# æª¢æŸ¥é»ç¯„ä¾‹

æ­¤ç¯„ä¾‹ç¤ºç¯„å¦‚ä½•ä½¿ç”¨ Semantic Kernel Graph æª¢æŸ¥é»ç³»çµ±é€²è¡ŒåŸ·è¡Œç‹€æ…‹çš„æŒä¹…åŒ–å’Œå¾©åŸã€‚å®ƒå±•ç¤ºäº†å¦‚ä½•ä¿å­˜ã€å¾©åŸå’Œç®¡ç†åŸ·è¡Œç‹€æ…‹ä»¥å¯¦ç¾æœ‰éŸŒæ€§çš„å·¥ä½œæµç¨‹ã€‚

## ç›®æ¨™

å­¸ç¿’å¦‚ä½•åœ¨åŸºæ–¼åœ–è¡¨çš„å·¥ä½œæµç¨‹ä¸­å¯¦ç¾æª¢æŸ¥é»åŠŸèƒ½ä»¥ï¼š
* åœ¨é—œéµé»ä¿å­˜åŸ·è¡Œç‹€æ…‹
* å¾å…ˆå‰çš„æª¢æŸ¥é»å¾©åŸå·¥ä½œæµç¨‹
* å¯¦ç¾è‡ªå‹•æª¢æŸ¥é»ç®¡ç†
* è™•ç†åˆ†æ•£å¼æª¢æŸ¥é»å„²å­˜
* ç›£æ§ä¸¦å„ªåŒ–æª¢æŸ¥é»æ•ˆèƒ½

## å…ˆæ±ºæ¢ä»¶

* **.NET 8.0** æˆ–æ›´æ–°ç‰ˆæœ¬
* **OpenAI API Key** åœ¨ `appsettings.json` ä¸­é…ç½®
* **Semantic Kernel Graph package** å·²å®‰è£
* å° [Graph Concepts](../concepts/graph-concepts.md) å’Œ [State Management](../concepts/state.md) çš„åŸºæœ¬ç†è§£

## é—œéµå…ƒä»¶

### æ¦‚å¿µå’ŒæŠ€è¡“

* **Checkpointing**: åœ¨ç‰¹å®šæ™‚é–“é»ä¿å­˜åŸ·è¡Œç‹€æ…‹ä»¥ä¾›ç¨å¾Œå¾©åŸ
* **State Serialization**: å°‡åœ–è¡¨ç‹€æ…‹è½‰æ›ç‚ºæŒä¹…å„²å­˜æ ¼å¼
* **Recovery**: å¾å·²ä¿å­˜çš„æª¢æŸ¥é»å¾©åŸå·¥ä½œæµç¨‹åŸ·è¡Œ
* **Distributed Storage**: åœ¨å¤šå€‹å„²å­˜ä½ç½®ç®¡ç†æª¢æŸ¥é»

### æ ¸å¿ƒé¡åˆ¥

* `CheckpointManager`: ç®¡ç†æª¢æŸ¥é»å»ºç«‹ã€å„²å­˜å’Œæª¢ç´¢
* `CheckpointingGraphExecutor`: å…·æœ‰å…§å»ºæª¢æŸ¥é»æ”¯æ´çš„åŸ·è¡Œå™¨
* `StateHelpers`: ç”¨æ–¼ç‹€æ…‹åºåˆ—åŒ–å’Œé©—è­‰çš„å·¥å…·ç¨‹å¼
* `CheckpointOptions`: æª¢æŸ¥é»è¡Œç‚ºçš„é…ç½®é¸é …

## åŸ·è¡Œæ­¤ç¯„ä¾‹

### å…¥é–€

æ­¤ç¯„ä¾‹ç¤ºç¯„ Semantic Kernel Graph package çš„æª¢æŸ¥é»å’Œç‹€æ…‹æŒä¹…åŒ–åŠŸèƒ½ã€‚ä»¥ä¸‹ç¨‹å¼ç¢¼ç‰‡æ®µå±•ç¤ºå¦‚ä½•åœ¨æ‚¨è‡ªå·±çš„æ‡‰ç”¨ç¨‹å¼ä¸­å¯¦ç¾æ­¤æ¨¡å¼ã€‚

## é€æ­¥å¯¦ç¾

### 1. åŸºæœ¬æª¢æŸ¥é»ç³»çµ±

æ­¤ç¯„ä¾‹ç¤ºç¯„åŸºæœ¬çš„æª¢æŸ¥é»å»ºç«‹å’Œå¾©åŸã€‚

```csharp
// Create kernel with checkpointing support
var kernel = CreateKernel();

// Create checkpointing executor
var checkpointingExecutor = new CheckpointingGraphExecutor(
    "CheckpointingExample",
    "Basic checkpointing demonstration",
    logger);

// Configure checkpoint options
var checkpointOptions = new CheckpointOptions
{
    EnableAutoCheckpointing = true,
    CheckpointInterval = 2, // Checkpoint every 2 nodes
    EnableCompression = true,
    MaxCheckpointSize = 1024 * 1024, // 1MB
    StorageProvider = new FileSystemStorageProvider("./checkpoints")
};

checkpointingExecutor.ConfigureCheckpointing(checkpointOptions);

// Create a simple workflow
var workflow = CreateCheckpointingWorkflow();
checkpointingExecutor.AddGraph(workflow);

// Execute with checkpointing
var arguments = new KernelArguments
{
    ["input_data"] = "Sample data for processing",
    ["checkpoint_id"] = Guid.NewGuid().ToString()
};

Console.WriteLine("ğŸš€ Starting workflow execution with checkpointing...");
var result = await checkpointingExecutor.ExecuteAsync(kernel, arguments);

Console.WriteLine($"âœ… Workflow completed. Final result: {result.GetValue<string>()}");
Console.WriteLine($"ğŸ“Š Checkpoints created: {checkpointingExecutor.CheckpointManager.GetCheckpointCount()}");
```

### 2. æª¢æŸ¥é»å¾©åŸç¯„ä¾‹

ç¤ºç¯„å¦‚ä½•å¾æª¢æŸ¥é»å¾©åŸå·¥ä½œæµç¨‹åŸ·è¡Œã€‚

```csharp
// Simulate workflow interruption and recovery
Console.WriteLine("\nğŸ”„ Simulating workflow interruption...");

// Create a long-running workflow
var longWorkflow = CreateLongRunningWorkflow();
var recoveryExecutor = new CheckpointingGraphExecutor(
    "RecoveryExample",
    "Checkpoint recovery demonstration",
    logger);

recoveryExecutor.ConfigureCheckpointing(new CheckpointOptions
{
    EnableAutoCheckpointing = true,
    CheckpointInterval = 1, // Checkpoint after each node
    EnableCompression = true,
    StorageProvider = new FileSystemStorageProvider("./recovery-checkpoints")
});

recoveryExecutor.AddGraph(longWorkflow);

// Start execution
var recoveryArgs = new KernelArguments
{
    ["workflow_id"] = "recovery_001",
    ["data"] = "Large dataset for processing"
};

try
{
    Console.WriteLine("ğŸš€ Starting long workflow...");
    var recoveryResult = await recoveryExecutor.ExecuteAsync(kernel, recoveryArgs);
    Console.WriteLine($"âœ… Workflow completed: {recoveryResult.GetValue<string>()}");
}
catch (OperationCanceledException)
{
    Console.WriteLine("â¸ï¸ Workflow was interrupted. Checkpoints saved.");
    
    // Simulate recovery
    Console.WriteLine("ğŸ”„ Recovering from checkpoint...");
    var recoveredResult = await recoveryExecutor.RecoverFromLatestCheckpointAsync(
        kernel, recoveryArgs);
    
    Console.WriteLine($"âœ… Recovery successful: {recoveredResult.GetValue<string>()}");
}
```

### 3. åˆ†æ•£å¼å‚™ä»½ç¯„ä¾‹

å±•ç¤ºå¦‚ä½•å¯¦ç¾åˆ†æ•£å¼æª¢æŸ¥é»å„²å­˜ä»¥å¯¦ç¾é«˜å¯ç”¨æ€§ã€‚

```csharp
// Create distributed storage providers
var localStorage = new FileSystemStorageProvider("./local-checkpoints");
var cloudStorage = new AzureBlobStorageProvider(connectionString, containerName);
var distributedStorage = new DistributedStorageProvider(new[]
{
    localStorage,
    cloudStorage
});

// Configure distributed checkpointing
var distributedExecutor = new CheckpointingGraphExecutor(
    "DistributedExample",
    "Distributed checkpointing demonstration",
    logger);

distributedExecutor.ConfigureCheckpointing(new CheckpointOptions
{
    EnableAutoCheckpointing = true,
    CheckpointInterval = 3,
    EnableCompression = true,
    StorageProvider = distributedStorage,
    ReplicationFactor = 2, // Store in 2 locations
    EnableAsyncBackup = true
});

// Create and execute workflow
var distributedWorkflow = CreateDistributedWorkflow();
distributedExecutor.AddGraph(distributedWorkflow);

var distributedArgs = new KernelArguments
{
    ["workflow_id"] = "distributed_001",
    ["data"] = "Critical data requiring backup"
};

Console.WriteLine("ğŸš€ Starting distributed checkpointing workflow...");
var distributedResult = await distributedExecutor.ExecuteAsync(kernel, distributedArgs);

Console.WriteLine($"âœ… Distributed workflow completed: {distributedResult.GetValue<string>()}");
Console.WriteLine($"ğŸ“Š Checkpoints stored in {distributedStorage.GetActiveProviders().Count()} locations");
```

### 4. ç›£æ§å’Œåˆ†æç¯„ä¾‹

ç¤ºç¯„æª¢æŸ¥é»ç›£æ§å’Œæ•ˆèƒ½åˆ†æã€‚

```csharp
// Create monitoring-enabled executor
var monitoringExecutor = new CheckpointingGraphExecutor(
    "MonitoringExample",
    "Checkpoint monitoring demonstration",
    logger);

monitoringExecutor.ConfigureCheckpointing(new CheckpointOptions
{
    EnableAutoCheckpointing = true,
    CheckpointInterval = 2,
    EnableCompression = true,
    StorageProvider = new FileSystemStorageProvider("./monitoring-checkpoints"),
    EnableMetrics = true,
    EnableDetailedLogging = true
});

// Subscribe to checkpoint events
monitoringExecutor.CheckpointManager.CheckpointCreated += (sender, e) =>
{
    Console.WriteLine($"ğŸ“ Checkpoint created: {e.CheckpointId} at {e.Timestamp}");
    Console.WriteLine($"   Size: {e.SizeBytes} bytes, Compression: {e.CompressionRatio:P1}");
};

monitoringExecutor.CheckpointManager.CheckpointRestored += (sender, e) =>
{
    Console.WriteLine($"ğŸ”„ Checkpoint restored: {e.CheckpointId} in {e.RestoreTimeMs}ms");
};

// Execute workflow with monitoring
var monitoringWorkflow = CreateMonitoringWorkflow();
monitoringExecutor.AddGraph(monitoringWorkflow);

var monitoringArgs = new KernelArguments
{
    ["workflow_id"] = "monitoring_001",
    ["data"] = "Data for monitoring demonstration"
};

Console.WriteLine("ğŸš€ Starting monitored workflow...");
var monitoringResult = await monitoringExecutor.ExecuteAsync(kernel, monitoringArgs);

// Display checkpoint analytics
var analytics = monitoringExecutor.CheckpointManager.GetAnalytics();
Console.WriteLine("\nğŸ“Š Checkpoint Analytics:");
Console.WriteLine($"   Total checkpoints: {analytics.TotalCheckpoints}");
Console.WriteLine($"   Average size: {analytics.AverageSizeBytes} bytes");
Console.WriteLine($"   Compression ratio: {analytics.AverageCompressionRatio:P1}");
Console.WriteLine($"   Storage efficiency: {analytics.StorageEfficiency:P1}");
```

## é æœŸè¼¸å‡º

### åŸºæœ¬æª¢æŸ¥é»ç¯„ä¾‹

```
ğŸš€ Starting workflow execution with checkpointing...
ğŸ“ Creating checkpoint after node: data-processor
ğŸ“ Creating checkpoint after node: data-validator
ğŸ“ Creating checkpoint after node: result-generator
âœ… Workflow completed. Final result: Processed data with validation
ğŸ“Š Checkpoints created: 3
ğŸ“ Checkpoints stored in: ./checkpoints/
   - checkpoint_001.json (2.3 KB)
   - checkpoint_002.json (2.1 KB)
   - checkpoint_003.json (1.8 KB)
```

### å¾©åŸç¯„ä¾‹

```
ğŸš€ Starting long workflow...
ğŸ“ Creating checkpoint after node: data-loader
ğŸ“ Creating checkpoint after node: data-processor
â¸ï¸ Workflow was interrupted. Checkpoints saved.

ğŸ”„ Recovering from checkpoint...
ğŸ“ Restoring from checkpoint: checkpoint_002.json
ğŸ”„ Resuming execution from node: data-validator
ğŸ“ Creating checkpoint after node: data-validator
ğŸ“ Creating checkpoint after node: result-generator
âœ… Recovery successful: Processed large dataset with recovery
ğŸ“Š Recovery time: 1.2 seconds
ğŸ“Š Checkpoints used: 1
```

### åˆ†æ•£å¼å‚™ä»½ç¯„ä¾‹

```
ğŸš€ Starting distributed checkpointing workflow...
ğŸ“ Creating checkpoint after node: data-processor
   ğŸ“¤ Backing up to local storage
   ğŸ“¤ Backing up to cloud storage
ğŸ“ Creating checkpoint after node: data-validator
   ğŸ“¤ Backing up to local storage
   ğŸ“¤ Backing up to cloud storage
ğŸ“ Creating checkpoint after node: result-generator
   ğŸ“¤ Backing up to local storage
   ğŸ“¤ Backing up to cloud storage

âœ… Distributed workflow completed: Critical data processed with backup
ğŸ“Š Checkpoints stored in 2 locations
ğŸ“ Local storage: 3 checkpoints
â˜ï¸ Cloud storage: 3 checkpoints
ğŸ”’ Replication factor: 2x
```

### ç›£æ§ç¯„ä¾‹

```
ğŸš€ Starting monitored workflow...
ğŸ“ Checkpoint created: cp_001 at 2025-08-15 10:30:15
   Size: 2048 bytes, Compression: 75.2%
ğŸ“ Checkpoint created: cp_002 at 2025-08-15 10:30:18
   Size: 1920 bytes, Compression: 78.1%
ğŸ“ Checkpoint created: cp_003 at 2025-08-15 10:30:21
   Size: 1856 bytes, Compression: 79.8%
ğŸ”„ Checkpoint restored: cp_002 in 45ms

âœ… Monitored workflow completed: Data processed with monitoring
ğŸ“Š Checkpoint Analytics:
   Total checkpoints: 3
   Average size: 1941 bytes
   Compression ratio: 77.7%
   Storage efficiency: 85.2%
```

## é…ç½®é¸é …

### æª¢æŸ¥é»é¸é …

```csharp
var checkpointOptions = new CheckpointOptions
{
    EnableAutoCheckpointing = true,           // Automatic checkpointing
    CheckpointInterval = 2,                   // Checkpoint every N nodes
    EnableCompression = true,                 // Compress checkpoint data
    MaxCheckpointSize = 1024 * 1024,         // Maximum checkpoint size
    StorageProvider = storageProvider,        // Storage provider
    ReplicationFactor = 2,                   // Number of storage locations
    EnableAsyncBackup = true,                // Asynchronous backup
    EnableMetrics = true,                    // Enable performance metrics
    EnableDetailedLogging = true,            // Detailed logging
    CompressionLevel = CompressionLevel.Optimal, // Compression level
    EncryptionEnabled = false,               // Enable encryption
    RetentionPolicy = new RetentionPolicy    // Checkpoint retention
    {
        MaxCheckpoints = 100,
        MaxAge = TimeSpan.FromDays(30),
        EnableAutoCleanup = true
    }
};
```

### å„²å­˜æä¾›è€…é…ç½®

```csharp
// File system storage
var fileStorage = new FileSystemStorageProvider("./checkpoints")
{
    MaxFileSize = 10 * 1024 * 1024,         // 10MB max file size
    EnableFileRotation = true,               // Rotate old files
    CompressionEnabled = true,               // Enable file compression
    EncryptionEnabled = false                // Disable encryption
};

// Azure Blob storage
var azureStorage = new AzureBlobStorageProvider(connectionString, containerName)
{
    BlobTier = BlobTier.Cool,                // Use cool tier for cost
    EnableSoftDelete = true,                 // Enable soft delete
    RetentionDays = 90,                      // 90-day retention
    EnableVersioning = true                  // Enable blob versioning
};

// Distributed storage
var distributedStorage = new DistributedStorageProvider(new[]
{
    fileStorage,
    azureStorage
})
{
    PrimaryProvider = fileStorage,            // Primary storage
    FailoverEnabled = true,                  // Enable failover
    ConsistencyLevel = ConsistencyLevel.Eventual, // Eventual consistency
    RetryPolicy = new ExponentialBackoffRetryPolicy(3, TimeSpan.FromSeconds(1))
};
```

## æ•…éšœæ’é™¤

### å¸¸è¦‹å•é¡Œ

#### æª¢æŸ¥é»å»ºç«‹å¤±æ•—
```bash
# Problem: Checkpoints fail to create
# Solution: Check storage permissions and disk space
EnableDetailedLogging = true;
StorageProvider = new FileSystemStorageProvider("./checkpoints");
```

#### æª¢æŸ¥é»æ“ä½œç·©æ…¢
```bash
# Problem: Checkpoint operations are slow
# Solution: Optimize compression and storage
CompressionLevel = CompressionLevel.Fastest;
EnableAsyncBackup = true;
StorageProvider = new FastStorageProvider();
```

#### å¾©åŸå¤±æ•—
```bash
# Problem: Checkpoint recovery fails
# Solution: Validate checkpoint integrity and storage
EnableCheckpointValidation = true;
ValidateOnRestore = true;
```

### é™¤éŒ¯æ¨¡å¼

å•Ÿç”¨è©³ç´°è¨˜éŒ„ä»¥é€²è¡Œæ•…éšœæ’é™¤ï¼š

```csharp
// Enable debug logging
var logger = LoggerFactory.Create(builder =>
{
    builder.AddConsole();
    builder.SetMinimumLevel(LogLevel.Debug);
}).CreateLogger<CheckpointingExample>();

// Configure executor with debug logging
var debugExecutor = new CheckpointingGraphExecutor(
    "DebugExample", "Debug checkpointing", logger);

debugExecutor.ConfigureCheckpointing(new CheckpointOptions
{
    EnableDetailedLogging = true,
    EnableMetrics = true,
    LogCheckpointOperations = true,
    LogStorageOperations = true
});
```

## é€²éšæ¨¡å¼

### è‡ªè¨‚æª¢æŸ¥é»è§¸ç™¼ç¨‹åº

```csharp
// Implement custom checkpoint triggers
var customTrigger = new CustomCheckpointTrigger
{
    ShouldCheckpoint = (context) =>
    {
        // Checkpoint on specific conditions
        var nodeId = context.CurrentNode?.NodeId;
        var executionStep = context.ExecutionStep;
        
        return nodeId == "critical-node" || 
               executionStep % 5 == 0 ||
               context.State.GetValue<int>("data_size") > 1000;
    }
};

checkpointingExecutor.CheckpointTrigger = customTrigger;
```

### å¢é‡æª¢æŸ¥é»

```csharp
// Implement incremental checkpointing for large states
var incrementalOptions = new IncrementalCheckpointOptions
{
    EnableIncrementalCheckpointing = true,
    IncrementThreshold = 1024 * 1024,        // 1MB threshold
    DeltaCompression = true,                 // Compress deltas
    MergeStrategy = MergeStrategy.Optimistic, // Optimistic merging
    ValidationStrategy = ValidationStrategy.Checksum // Checksum validation
};

checkpointingExecutor.ConfigureIncrementalCheckpointing(incrementalOptions);
```

### æª¢æŸ¥é»å”èª¿

```csharp
// Orchestrate checkpoints across multiple workflows
var orchestrator = new CheckpointOrchestrator
{
    GlobalCheckpointInterval = TimeSpan.FromMinutes(5),
    WorkflowDependencies = new Dictionary<string, string[]>
    {
        ["workflow_a"] = new[] { "workflow_b", "workflow_c" },
        ["workflow_b"] = new[] { "workflow_d" },
        ["workflow_c"] = new[] { "workflow_d" }
    },
    CheckpointStrategy = CheckpointStrategy.DependencyAware
};

orchestrator.RegisterWorkflow(checkpointingExecutor);
orchestrator.StartOrchestration();
```

## ç›¸é—œç¯„ä¾‹

* [State Management](./state-management.md): åœ–è¡¨ç‹€æ…‹å’Œå¼•æ•¸è™•ç†
* [Streaming Execution](./streaming-execution.md): å³æ™‚åŸ·è¡Œç›£æ§
* [Multi-Agent](./multi-agent.md): å”èª¿çš„å¤šä»£ç†å·¥ä½œæµç¨‹
* [Graph Metrics](./graph-metrics.md): æ•ˆèƒ½ç›£æ§å’Œå„ªåŒ–

## åƒé–±

* [Checkpointing Concepts](../concepts/checkpointing.md): ç­è§£ç‹€æ…‹æŒä¹…åŒ–
* [State Management](../concepts/state.md): Graph ç‹€æ…‹åŸºç¤
* [Performance Monitoring](../how-to/metrics-and-observability.md): æŒ‡æ¨™å’Œå„ªåŒ–
* [API Reference](../api/): å®Œæ•´ API æ–‡ä»¶
